{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNdV0YOTmn+ZLzgRSsBdx3D"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pki1jvlkPQHG",
        "outputId": "cd455e7b-1034-4f6b-90da-8835768b1dcb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.16.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.5.3)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install scikit-learn numpy"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install mediapipe opencv-python"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8G3aXWT7QXCU",
        "outputId": "e7e1ee87-7bd5-4502-879d-ffa11b095822"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: mediapipe in /usr/local/lib/python3.12/dist-packages (0.10.32)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.12/dist-packages (4.13.0.92)\n",
            "Requirement already satisfied: absl-py~=2.3 in /usr/local/lib/python3.12/dist-packages (from mediapipe) (2.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from mediapipe) (2.0.2)\n",
            "Requirement already satisfied: sounddevice~=0.5 in /usr/local/lib/python3.12/dist-packages (from mediapipe) (0.5.5)\n",
            "Requirement already satisfied: flatbuffers~=25.9 in /usr/local/lib/python3.12/dist-packages (from mediapipe) (25.12.19)\n",
            "Requirement already satisfied: opencv-contrib-python in /usr/local/lib/python3.12/dist-packages (from mediapipe) (4.13.0.92)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from mediapipe) (3.10.0)\n",
            "Requirement already satisfied: cffi in /usr/local/lib/python3.12/dist-packages (from sounddevice~=0.5->mediapipe) (2.0.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->mediapipe) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib->mediapipe) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->mediapipe) (4.61.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->mediapipe) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->mediapipe) (26.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib->mediapipe) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->mediapipe) (3.3.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib->mediapipe) (2.9.0.post0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib->mediapipe) (1.17.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi->sounddevice~=0.5->mediapipe) (3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import mediapipe as mp\n",
        "print(mp.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QZUnTbxaQyom",
        "outputId": "620293db-6df5-421e-b39d-369243c7aeb8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.10.32\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -q https://storage.googleapis.com/mediapipe-models/hand_landmarker/hand_landmarker/float16/1/hand_landmarker.task"
      ],
      "metadata": {
        "id": "6lFK29txRjCm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import mediapipe as mp\n",
        "import numpy as np\n",
        "from mediapipe.tasks import python\n",
        "from mediapipe.tasks.python import vision\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "# Setup model\n",
        "base_options = python.BaseOptions(model_asset_path=\"hand_landmarker.task\")\n",
        "\n",
        "options = vision.HandLandmarkerOptions(\n",
        "    base_options=base_options,\n",
        "    num_hands=2\n",
        ")\n",
        "\n",
        "detector = vision.HandLandmarker.create_from_options(options)"
      ],
      "metadata": {
        "id": "s5LjIB3gPmIn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cap = cv2.VideoCapture(0)\n",
        "ret, frame = cap.read()\n",
        "cap.release()\n",
        "\n",
        "if ret:\n",
        "    rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    mp_image = mp.Image(\n",
        "        image_format=mp.ImageFormat.SRGB,\n",
        "        data=rgb\n",
        "    )\n",
        "\n",
        "    result = detector.detect(mp_image)\n",
        "\n",
        "    print(\"Hands detected:\", len(result.hand_landmarks))\n",
        "\n",
        "    cv2_imshow(frame)"
      ],
      "metadata": {
        "id": "QTEn_7s7RrXM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab.output import eval_js\n",
        "from base64 import b64decode\n",
        "from IPython.display import display, Javascript\n",
        "from PIL import Image\n",
        "import io\n",
        "\n",
        "def capture_image():\n",
        "    display(Javascript('''\n",
        "        async function capture() {\n",
        "            const div = document.createElement('div');\n",
        "            const video = document.createElement('video');\n",
        "            const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
        "            document.body.appendChild(div);\n",
        "            div.appendChild(video);\n",
        "            video.srcObject = stream;\n",
        "            await video.play();\n",
        "\n",
        "            await new Promise(resolve => setTimeout(resolve, 2000));\n",
        "\n",
        "            const canvas = document.createElement('canvas');\n",
        "            canvas.width = video.videoWidth;\n",
        "            canvas.height = video.videoHeight;\n",
        "            canvas.getContext('2d').drawImage(video, 0, 0);\n",
        "            stream.getTracks().forEach(track => track.stop());\n",
        "            div.remove();\n",
        "\n",
        "            return canvas.toDataURL('image/jpeg');\n",
        "        }\n",
        "        capture();\n",
        "    '''))\n",
        "\n",
        "    data = eval_js(\"capture()\")\n",
        "    binary = b64decode(data.split(',')[1])\n",
        "    return np.array(Image.open(io.BytesIO(binary)))\n",
        "\n",
        "frame = capture_image()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "YyxRb_kPRyVW",
        "outputId": "93ae488e-e7bb-4483-bc40-6c96b4d6ebbd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        async function capture() {\n",
              "            const div = document.createElement('div');\n",
              "            const video = document.createElement('video');\n",
              "            const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
              "            document.body.appendChild(div);\n",
              "            div.appendChild(video);\n",
              "            video.srcObject = stream;\n",
              "            await video.play();\n",
              "\n",
              "            await new Promise(resolve => setTimeout(resolve, 2000));\n",
              "\n",
              "            const canvas = document.createElement('canvas');\n",
              "            canvas.width = video.videoWidth;\n",
              "            canvas.height = video.videoHeight;\n",
              "            canvas.getContext('2d').drawImage(video, 0, 0);\n",
              "            stream.getTracks().forEach(track => track.stop());\n",
              "            div.remove();\n",
              "\n",
              "            return canvas.toDataURL('image/jpeg');\n",
              "        }\n",
              "        capture();\n",
              "    "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "mp_image = mp.Image(\n",
        "    image_format=mp.ImageFormat.SRGB,\n",
        "    data=rgb\n",
        ")\n",
        "\n",
        "result = detector.detect(mp_image)\n",
        "\n",
        "if result.hand_landmarks:\n",
        "    landmarks = []\n",
        "    for lm in result.hand_landmarks[0]:\n",
        "        landmarks.extend([lm.x, lm.y, lm.z])\n",
        "\n",
        "    print(\"Feature vector length:\", len(landmarks))  # Should be 63\n",
        "else:\n",
        "    print(\"No hand detected\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0T5vgyNYR9GD",
        "outputId": "fb1c7b16-3efc-452f-eb51-8fa4f6524b3e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No hand detected\n"
          ]
        }
      ]
    }
  ]
}